{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = Path(\"../data/processed/consumo_tarifas_meses.xlsx\").resolve()\n",
    "\n",
    "data = pd.read_excel(processed_data_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar formato da columa Meses\n",
    "data[\"Meses\"] = data[\"Meses\"].apply(lambda x: int(str(x).split(\".\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Item Faturamento BW\"] = data[\"Item Faturamento BW\"].apply(lambda x: str(x).replace(\" \",\"\"))\n",
    "for i, item in enumerate(np.sort(data[\"Item Faturamento BW\"].unique())):\n",
    "    print(f\"{i+1:02d} - {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SubAgrupador de Fatu\"] = data[\"SubAgrupador de Fatu\"].apply(lambda x: str(x).replace(\" \",\"\"))\n",
    "for i, item in enumerate(np.sort(data[\"SubAgrupador de Fatu\"].unique())):\n",
    "    print(f\"{i+1:02d} - {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"grupo\"] = data[\"grupo\"].apply(lambda x: str(x).replace(\" \",\"\"))\n",
    "for i, item in enumerate(np.sort(data[\"grupo\"].unique())):\n",
    "    print(f\"{i+1:02d} - {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    'Empresa',\n",
    "    'Nº instalação',\n",
    "    \"Meses\"\n",
    "    ]\n",
    "\n",
    "columns = \"Item Faturamento BW\"\n",
    "value = \"Valores\"\n",
    "\n",
    "data_piv = pd.pivot_table(data, values=value, index=index, columns=columns)\n",
    "\n",
    "data_piv = data_piv.reset_index()\n",
    "\n",
    "data_piv[\"EnergAtvInj.mUCoPT-FPTE\"] = data_piv[\"EnergAtvInj.mUCoPT-FPTE\"] + data_piv[\"EnergAtvInj.mUCoPT-FP-TE\"]\n",
    "data_piv = data_piv.drop(\"EnergAtvInj.mUCoPT-FP-TE\", axis=1)\n",
    "data_piv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat = pd.DataFrame()\n",
    "keys = [\"Nº instalação\", \"SubAgrupador de Fatu\"]\n",
    "\n",
    "for (cliente, grupo), grouped_df in data.groupby(by=keys):\n",
    "    \n",
    "    keys_2 = keys.copy()\n",
    "    keys_2.append(\"Meses\")\n",
    "    df_tmp = pd.DataFrame()\n",
    "    df_tmp[\"cliente\"] = cliente,\n",
    "    df_tmp[\"grupo\"] = grupo,\n",
    "    df_tmp[\"count\"] = grouped_df[\"Meses\"].unique().shape[0],\n",
    "    df_tmp[\"last\"] = grouped_df[\"Meses\"].max(),\n",
    "    df_tmp[\"mean\"] = float(round(grouped_df.groupby(keys_2).sum()[\"Valores\"].mean(),4)),\n",
    "    df_tmp[\"max\"] = float(round(grouped_df.groupby(keys_2).sum()[\"Valores\"].max(),4)),\n",
    "    df_tmp[\"min\"] = float(round(grouped_df.groupby(keys_2).sum()[\"Valores\"].min(),4)),\n",
    "    df_tmp[\"total\"] = float(round(grouped_df.groupby(keys_2).sum()[\"Valores\"].sum(),4)),\n",
    "    df_tmp[\"amplitude\"] = df_tmp[\"max\"] - df_tmp[\"min\"]\n",
    "    df_tmp[\"std\"] = float(round(grouped_df.groupby(keys_2).sum()[\"Valores\"].std(),4))\n",
    "    # break\n",
    "    data_feat = pd.concat([data_feat, df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [\n",
    "    \"count\",\n",
    "    \"last\",\n",
    "    \"mean\",\n",
    "    \"max\",\n",
    "    \"min\",\n",
    "    \"total\",\n",
    "    \"amplitude\",\n",
    "    \"std\"\n",
    "]\n",
    "\n",
    "data_feat_pivot = pd.pivot_table(data_feat, values=values, columns=\"grupo\", index=\"cliente\")\n",
    "data_feat_pivot.columns = ['_'.join(col).strip() for col in data_feat_pivot.columns]\n",
    "data_feat_pivot = data_feat_pivot.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.scatter(data_feat_pivot, x=\"total_Consumo\", y=\"total_Injetada\", hover_data=\"cliente\")\n",
    "sns.scatterplot(data_feat_pivot, x=\"total_Consumo\", y=\"total_Injetada\", palette=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler, MinMaxScaler, RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_columns = [\"total_Consumo\", \"total_Injetada\"]#, \"total_TUSD\"]\n",
    "data_interest = data_feat_pivot[interest_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_count = len(interest_columns)\n",
    "fig, ax = plt.subplots(col_count, 1, figsize=(col_count*5, 6))\n",
    "for i, col in enumerate(interest_columns):\n",
    "\n",
    "    sns.histplot(data_interest, x=col, ax=ax[i])\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_count = len(interest_columns)\n",
    "fig, ax = plt.subplots(1, col_count, figsize=(12, 5))\n",
    "for i, col in enumerate(interest_columns):\n",
    "    sns.boxplot(data_interest, y=col, ax=ax[i])\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data_interest.quantile(0.25)\n",
    "q3 = data_interest.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "outlier_mask = ((data_interest < (q1 - 1.5*iqr)) | (data_interest > (q3+1.5*iqr))).any(axis=1)\n",
    "data_feat_pivot[\"out_iqr\"] = 0\n",
    "data_feat_pivot.loc[outlier_mask, \"out_iqr\"] = -1\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "sns.scatterplot(data_feat_pivot, x=\"total_Consumo\", y=\"total_Injetada\", hue=\"out_iqr\", palette=\"Set1\", ax=ax[0])\n",
    "sns.scatterplot(data_feat_pivot, x=\"total_Consumo\", y=\"total_TUSD\", hue=\"out_iqr\", palette=\"Set1\", ax=ax[1])\n",
    "sns.scatterplot(data_feat_pivot, x=\"total_Injetada\", y=\"total_TUSD\", hue=\"out_iqr\", palette=\"Set1\", ax=ax[2])\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data_interest.fillna(0)\n",
    "clusterizer = DBSCAN(eps=100000,min_samples=10)\n",
    "clusters = clusterizer.fit_predict(X_data)\n",
    "data_feat_pivot[\"out_dbscan\"] = clusters\n",
    "print(data_feat_pivot[\"out_dbscan\"].value_counts())\n",
    "sns.scatterplot(data_feat_pivot, x=\"total_Consumo\", y=\"total_Injetada\", hue=\"out_dbscan\", palette=\"Set1\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_feat_pivot.loc[\n",
    "    # :,\n",
    "    (data_feat_pivot[[\"out_iqr\", \"out_dbscan\"]]!=-1).all(axis=1),\n",
    "    (data_feat_pivot.columns.str.contains(\"Consumo\")) | (data_feat_pivot.columns.str.contains(\"Injetada\")) | (data_feat_pivot.columns.str.contains(\"_TUSD\"))\n",
    "    ].fillna(0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizer = Normalizer()\n",
    "# normalizer = MaxAbsScaler()\n",
    "# normalizer = MinMaxScaler()\n",
    "normalizer = StandardScaler()\n",
    "# normalizer = RobustScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "\n",
    "inertias = []\n",
    "k_range = list(range(2, 11)) \n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_normalized)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(k_range, inertias)\n",
    "plt.ylabel(\"Inercias\")\n",
    "plt.xlabel(\"Numero Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = PCA(n_components=2, random_state=42)\n",
    "X_reduced = reduction.fit_transform(X_normalized)\n",
    "print(f\"Explained Variance Ratio: {reduction.explained_variance_ratio_}\")\n",
    "\n",
    "k = 6 # based on elbon plot\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "labels = kmeans.fit_predict(X_normalized)\n",
    "X[\"cluster\"] = labels\n",
    "\n",
    "df = pd.DataFrame(X_reduced)\n",
    "df[\"cluster\"] = labels\n",
    "print(f\"Clusters count\")\n",
    "print(df[\"cluster\"].value_counts())\n",
    "# Plot reduction\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(df, x=1, y=0, hue=\"cluster\", palette=\"Set1\", ax=ax1)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# plot original data\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(X, x=\"total_Consumo\", y=\"total_Injetada\", hue=\"cluster\", palette=\"Set1\", ax=ax2)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat_pivot = pd.merge(data_feat_pivot, X[[\"cluster\"]], how=\"left\", left_index=True, right_index=True)\n",
    "data_feat_pivot[\"cluster\"] = data_feat_pivot[\"cluster\"].fillna(-1)\n",
    "data_feat_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data_feat_pivot, x=\"cluster\", y=\"mean_TUSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(X,x=\"cluster\", y=\"total_Injetada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(X,x=\"cluster\", y=\"total_Consumo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X[\"cluster\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizer = Normalizer()\n",
    "# normalizer = MaxAbsScaler()\n",
    "# normalizer = MinMaxScaler()\n",
    "normalizer = StandardScaler()\n",
    "# normalizer = RobustScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "\n",
    "reduction = PCA(n_components=2, random_state=42)\n",
    "X_reduced = reduction.fit_transform(X_normalized)\n",
    "print(f\"Explained Variance Ratio: {reduction.explained_variance_ratio_}\")\n",
    "\n",
    "clusterizer = DBSCAN(eps=2)\n",
    "labels = clusterizer.fit_predict(X_normalized)\n",
    "X[\"cluster\"] = labels\n",
    "\n",
    "df = pd.DataFrame(X_reduced)\n",
    "df[\"cluster\"] = labels\n",
    "print(f\"Clusters count\")\n",
    "print(df[\"cluster\"].value_counts())\n",
    "# Plot reduction\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(df, x=1, y=0, hue=\"cluster\", palette=\"Set1\", ax=ax1)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# plot original data\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(X, x=\"total_Consumo\", y=\"total_Injetada\", hue=\"cluster\", palette=\"Set1\", ax=ax2)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Finding optimal number of clusters using the Elbow Method\n",
    "inertias = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, 11), inertias, 'o-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Initialize and fit K-means\n",
    "# kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "# clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# Fit Agglomerative Clustering\n",
    "# agg_clustering = AgglomerativeClustering(n_clusters=2)\n",
    "# agg_clusters = agg_clustering.fit_predict(X)\n",
    "\n",
    "dbscan = DBSCAN(eps=2, min_samples=5)\n",
    "db_clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "x_cluster = X.copy()\n",
    "x_cluster[\"cluster\"] = db_clusters\n",
    "var_list = X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cluster[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cltr in x_cluster[\"cluster\"].unique():\n",
    "    df_temp = x_cluster.loc[x_cluster[\"cluster\"]==cltr]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    sns.boxenplot(df_temp)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for clusters in clusters\n",
    "sns.boxplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x=\"Valores\", color=\"Item Faturamento BW\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data[\"Item Faturamento BW\"].unique():\n",
    "    data_filtered = data.loc[data[\"Item Faturamento BW\"] == item]\n",
    "    plt.figure(figsize=(10,3))\n",
    "    ax = sns.histplot(data_filtered, x=\"Valores\")\n",
    "    ax.set_title(item)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data[\"Item Faturamento BW\"].unique():\n",
    "    data_filtered = data.loc[data[\"Item Faturamento BW\"] == item]\n",
    "\n",
    "    # Create subplots (2 rows, 1 column)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 6), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    # Boxplot (First subplot)\n",
    "    sns.boxplot(data=data_filtered, x=\"Meses\", y=\"Valores\", ax=axes[0])\n",
    "    axes[0].set_title(f\"{item}\")\n",
    "\n",
    "    # Remove X-axis markers from the boxplot\n",
    "    axes[0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "    # Barplot (Second subplot) - Count occurrences of each month\n",
    "    month_counts = data_filtered[\"Meses\"].value_counts().reset_index()\n",
    "    month_counts.columns = [\"Meses\", \"Count\"]\n",
    "    barplot = sns.barplot(data=month_counts, x=\"Meses\", y=\"Count\", ax=axes[1])\n",
    "\n",
    "    # Remove spines (contours)\n",
    "    for spine in [\"top\", \"right\", \"left\", \"bottom\"]:\n",
    "        axes[0].spines[spine].set_visible(False)\n",
    "        axes[1].spines[spine].set_visible(False)\n",
    "\n",
    "    # Add value labels to bars\n",
    "    for p in barplot.patches:\n",
    "        axes[1].annotate(f'{p.get_height()}', \n",
    "                         (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                         ha='center', va='bottom', fontsize=10,)\n",
    "\n",
    "    # axes[1].set_title(f\"Count of Occurrences for {item}\")\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_occ = data[[\"Item Faturamento BW\", \"Meses\", \"Valores\"]].groupby([\"Item Faturamento BW\", \"Meses\"]).count()\n",
    "item_occ = item_occ.reset_index()\n",
    "item_occ[\"Meses\"] = item_occ[\"Meses\"].astype(str)\n",
    "item_occ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(item_occ,x=\"Meses\", y=\"Valores\", color=\"Item Faturamento BW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (a, b,c,d), df  in data.groupby([\"Empresa\", \"Classe de cálculo\", \"SubGrupo de Tensão\", \"Município\"]):\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    print(d)\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fapergs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
